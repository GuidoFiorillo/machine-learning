{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgON929r52GNFcMDdIj6n4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuidoFiorillo/machine-learning/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCkQsTKpgHNW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "0dd41b7a-4d31-4c38-e91c-f0d04b9985f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIJtgVeyjPTq",
        "outputId": "0b402ff2-885e-40b6-9511-c151b3caec0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t2YvXBejSgV",
        "outputId": "082b5892-490b-4c8e-e3df-a53227123149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.shortcut-targets-by-id',\n",
              " 'MyDrive',\n",
              " 'Shareddrives',\n",
              " '.file-revisions-by-id',\n",
              " '.Trash-0']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxHg-ZfKjbbQ",
        "outputId": "fd3db9ef-d6dc-480f-ea7a-b219d8d71405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Transponder verification test scenarios.docx',\n",
              " 'results.7z',\n",
              " 'results.zip',\n",
              " 'Risposte ad osservazioni di Thales.docx',\n",
              " '20220405 Transponder verification test scenarios - v1.0.docx',\n",
              " 'Understanding Machine Learning From Theory to Algorithms by Shalev-Shwartz S., Ben-David S. (z-lib.org).gdoc',\n",
              " 'Colab Notebooks',\n",
              " 'promessi sposi.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "Y4t5_euyjp_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"/content/drive/MyDrive/promessi sposi.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "6t2bEb5Oj0R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text[0:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "JgShqTSNkB7P",
        "outputId": "7d139077-fe79-4b09-cb53-4e94208620e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"l\\'historia si può veramente deffinire una guerra illustre contro il tempo, perché togliendoli di mano gl\\'anni suoi prigionieri, anzi già fatti cadaueri, li richiama in vita, li passa in rassegna, e li schiera di nuovo in battaglia. ma gl\\'illustri campioni che in tal arringo fanno messe di palme e d\\'allori, rapiscono solo che le sole spoglie più sfarzose e brillanti, imbalsamando co\\' loro inchiostri le imprese de prencipi e potentati, e qualificati personaggj, e trapontando coll\\'ago finissimo dell\\'ingegno i fili d\\'oro e di seta, che formano un perpetuo ricamo di attioni gloriose. però alla mia debolezza non è lecito solleuarsi a tal\\'argomenti, e sublimità pericolose, con aggirarsi tra labirinti de\\' politici maneggj, et il rimbombo de\\' bellici oricalchi: solo che hauendo hauuto notitia di fatti memorabili, se ben capitorno a gente meccaniche, e di piccol affare, mi accingo di lasciarne memoria a posteri, con far di tutto schietta e genuinamente il racconto, ouuero sia relatione. nella q'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIrKwIoskDbB",
        "outputId": "ed67e904-2a98-4c15-d440-1001f7c2b7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "v6mvWURplGXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDl1ZDyDlWyP",
        "outputId": "e4ada394-70be-41e8-e51d-3a126d951305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " \"'\": 4,\n",
              " '(': 5,\n",
              " ')': 6,\n",
              " '*': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '?': 23,\n",
              " 'a': 24,\n",
              " 'b': 25,\n",
              " 'c': 26,\n",
              " 'd': 27,\n",
              " 'e': 28,\n",
              " 'f': 29,\n",
              " 'g': 30,\n",
              " 'h': 31,\n",
              " 'i': 32,\n",
              " 'j': 33,\n",
              " 'l': 34,\n",
              " 'm': 35,\n",
              " 'n': 36,\n",
              " 'o': 37,\n",
              " 'p': 38,\n",
              " 'q': 39,\n",
              " 'r': 40,\n",
              " 's': 41,\n",
              " 't': 42,\n",
              " 'u': 43,\n",
              " 'v': 44,\n",
              " 'w': 45,\n",
              " 'x': 46,\n",
              " 'y': 47,\n",
              " 'z': 48,\n",
              " '§': 49,\n",
              " 'à': 50,\n",
              " 'á': 51,\n",
              " 'è': 52,\n",
              " 'é': 53,\n",
              " 'ì': 54,\n",
              " 'ñ': 55,\n",
              " 'ò': 56,\n",
              " 'ù': 57,\n",
              " '–': 58}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3MjkiJ9lYR7",
        "outputId": "7a330146-a8a5-448e-97a0-9e5102404cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  1306968\n",
            "Total Vocab:  59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AESc6asKlgEP",
        "outputId": "dcdab753-cf30-4974-c44c-df2b62079c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  1306868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "metadata": {
        "id": "Vm2b16bPmDiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm8BsJSbmhBN",
        "outputId": "4819cb12-7a31-4810-e45f-db9f2dcc8000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1306868, 100, 1)\n",
            "(1306868, 59)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "fRLwRGIXmnxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"/content/drive/MyDrive/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "rvifXn05nuwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8v8GuhJn7QA",
        "outputId": "e75a1d6a-3868-4d81-9a82-cc026ce018ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 2.6871\n",
            "Epoch 1: loss improved from inf to 2.68706, saving model to /content/drive/MyDrive/weights-improvement-01-2.6871.hdf5\n",
            "10210/10210 [==============================] - 372s 36ms/step - loss: 2.6871\n",
            "Epoch 2/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 2.4473\n",
            "Epoch 2: loss improved from 2.68706 to 2.44732, saving model to /content/drive/MyDrive/weights-improvement-02-2.4473.hdf5\n",
            "10210/10210 [==============================] - 370s 36ms/step - loss: 2.4473\n",
            "Epoch 3/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 2.2889\n",
            "Epoch 3: loss improved from 2.44732 to 2.28884, saving model to /content/drive/MyDrive/weights-improvement-03-2.2888.hdf5\n",
            "10210/10210 [==============================] - 367s 36ms/step - loss: 2.2888\n",
            "Epoch 4/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 2.1919\n",
            "Epoch 4: loss improved from 2.28884 to 2.19189, saving model to /content/drive/MyDrive/weights-improvement-04-2.1919.hdf5\n",
            "10210/10210 [==============================] - 366s 36ms/step - loss: 2.1919\n",
            "Epoch 5/20\n",
            "10210/10210 [==============================] - ETA: 0s - loss: 2.1272\n",
            "Epoch 5: loss improved from 2.19189 to 2.12717, saving model to /content/drive/MyDrive/weights-improvement-05-2.1272.hdf5\n",
            "10210/10210 [==============================] - 368s 36ms/step - loss: 2.1272\n",
            "Epoch 6/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 2.0775\n",
            "Epoch 6: loss improved from 2.12717 to 2.07753, saving model to /content/drive/MyDrive/weights-improvement-06-2.0775.hdf5\n",
            "10210/10210 [==============================] - 368s 36ms/step - loss: 2.0775\n",
            "Epoch 7/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 2.0397\n",
            "Epoch 7: loss improved from 2.07753 to 2.03964, saving model to /content/drive/MyDrive/weights-improvement-07-2.0396.hdf5\n",
            "10210/10210 [==============================] - 367s 36ms/step - loss: 2.0396\n",
            "Epoch 8/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 2.0076\n",
            "Epoch 8: loss improved from 2.03964 to 2.00756, saving model to /content/drive/MyDrive/weights-improvement-08-2.0076.hdf5\n",
            "10210/10210 [==============================] - 367s 36ms/step - loss: 2.0076\n",
            "Epoch 9/20\n",
            "10210/10210 [==============================] - ETA: 0s - loss: 1.9812\n",
            "Epoch 9: loss improved from 2.00756 to 1.98119, saving model to /content/drive/MyDrive/weights-improvement-09-1.9812.hdf5\n",
            "10210/10210 [==============================] - 368s 36ms/step - loss: 1.9812\n",
            "Epoch 10/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.9581\n",
            "Epoch 10: loss improved from 1.98119 to 1.95814, saving model to /content/drive/MyDrive/weights-improvement-10-1.9581.hdf5\n",
            "10210/10210 [==============================] - 368s 36ms/step - loss: 1.9581\n",
            "Epoch 11/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.9392\n",
            "Epoch 11: loss improved from 1.95814 to 1.93918, saving model to /content/drive/MyDrive/weights-improvement-11-1.9392.hdf5\n",
            "10210/10210 [==============================] - 365s 36ms/step - loss: 1.9392\n",
            "Epoch 12/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.9217\n",
            "Epoch 12: loss improved from 1.93918 to 1.92168, saving model to /content/drive/MyDrive/weights-improvement-12-1.9217.hdf5\n",
            "10210/10210 [==============================] - 367s 36ms/step - loss: 1.9217\n",
            "Epoch 13/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.9063\n",
            "Epoch 13: loss improved from 1.92168 to 1.90628, saving model to /content/drive/MyDrive/weights-improvement-13-1.9063.hdf5\n",
            "10210/10210 [==============================] - 365s 36ms/step - loss: 1.9063\n",
            "Epoch 14/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.8931\n",
            "Epoch 14: loss improved from 1.90628 to 1.89308, saving model to /content/drive/MyDrive/weights-improvement-14-1.8931.hdf5\n",
            "10210/10210 [==============================] - 366s 36ms/step - loss: 1.8931\n",
            "Epoch 15/20\n",
            "10210/10210 [==============================] - ETA: 0s - loss: 1.8810\n",
            "Epoch 15: loss improved from 1.89308 to 1.88103, saving model to /content/drive/MyDrive/weights-improvement-15-1.8810.hdf5\n",
            "10210/10210 [==============================] - 367s 36ms/step - loss: 1.8810\n",
            "Epoch 16/20\n",
            "10210/10210 [==============================] - ETA: 0s - loss: 1.8689\n",
            "Epoch 16: loss improved from 1.88103 to 1.86888, saving model to /content/drive/MyDrive/weights-improvement-16-1.8689.hdf5\n",
            "10210/10210 [==============================] - 369s 36ms/step - loss: 1.8689\n",
            "Epoch 17/20\n",
            "10210/10210 [==============================] - ETA: 0s - loss: 1.8588\n",
            "Epoch 17: loss improved from 1.86888 to 1.85881, saving model to /content/drive/MyDrive/weights-improvement-17-1.8588.hdf5\n",
            "10210/10210 [==============================] - 370s 36ms/step - loss: 1.8588\n",
            "Epoch 18/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.8499\n",
            "Epoch 18: loss improved from 1.85881 to 1.84991, saving model to /content/drive/MyDrive/weights-improvement-18-1.8499.hdf5\n",
            "10210/10210 [==============================] - 367s 36ms/step - loss: 1.8499\n",
            "Epoch 19/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.8409\n",
            "Epoch 19: loss improved from 1.84991 to 1.84093, saving model to /content/drive/MyDrive/weights-improvement-19-1.8409.hdf5\n",
            "10210/10210 [==============================] - 367s 36ms/step - loss: 1.8409\n",
            "Epoch 20/20\n",
            "10209/10210 [============================>.] - ETA: 0s - loss: 1.8327\n",
            "Epoch 20: loss improved from 1.84093 to 1.83271, saving model to /content/drive/MyDrive/weights-improvement-20-1.8327.hdf5\n",
            "10210/10210 [==============================] - 368s 36ms/step - loss: 1.8327\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc4ad2dad0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char=dict((i,c) for c,i in char_to_int.items())\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTNlspJ9Fdxx",
        "outputId": "4c084ae1-fffe-4006-a374-bdf79b12da60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" otessi sapere che quel pover'uomo fosse morto bene. a buon conto, finora ho detto per lui de' patern \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate characters\n",
        "# define the LSTM model\n",
        "from keras.layers import Lambda\n",
        "#set temperature\n",
        "temp=1.0\n",
        "\n",
        "model_trained = Sequential()\n",
        "model_trained.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model_trained.add(Dropout(0.2))\n",
        "model_trained.add(Lambda(lambda x: x / temp))\n",
        "model_trained.add(Dense(y.shape[1], activation='softmax'))\n",
        "filename = \"/content/drive/MyDrive/weights-improvement-20-1.8327.hdf5\"\n",
        "model_trained.load_weights(filename)\n",
        "model_trained.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "D8L8RZdZF82w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E7JaXmK1LOXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text=str([int_to_char[c] for c in [dataX[start]]])\n",
        "for i in range(100):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model_trained.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tgenerated_text+=result\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(generated_text)\n",
        "print (\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wpb3LPYFLItX",
        "outputId": "26d5469c-b753-4973-a6b5-eb4e1440be38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c2f648f14905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerated_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataX' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w1NNJhyxLP3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}